{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnhathcmus\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/blue/thai/hoangx/projects/explain-representation/wandb/run-20250218_230531-g1bm7gd0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nhathcmus/explain-representation/runs/g1bm7gd0' target=\"_blank\">jumping-dawn-108</a></strong> to <a href='https://wandb.ai/nhathcmus/explain-representation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nhathcmus/explain-representation' target=\"_blank\">https://wandb.ai/nhathcmus/explain-representation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nhathcmus/explain-representation/runs/g1bm7gd0' target=\"_blank\">https://wandb.ai/nhathcmus/explain-representation/runs/g1bm7gd0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "import wandb\n",
    "import numpy as np\n",
    "import torch\n",
    "import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from exrep.registry import load_data, save_data, load_model, load_tensor, get_artifact, save_tensor\n",
    "\n",
    "if 'notebooks' in os.getcwd():\n",
    "    os.chdir(\"../\")\n",
    "\n",
    "local_config = dotenv_values(\".env\")\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "embedding_artifact_name = \"imagenet-1k-first-20-take-2000_target-embeddings_mocov3-resnet50\"\n",
    "image_artifact_name = \"imagenet-1k-first-20-take-2000_images\"\n",
    "output_phase_name = \"surrogate\"\n",
    "\n",
    "run = wandb.init(\n",
    "    project=local_config[\"WANDB_PROJECT\"],\n",
    "    config={\n",
    "        \"job_type\": \"concept_attribution\",\n",
    "        \"num_clusters\": 20,\n",
    "    },\n",
    "    # reinit=True,\n",
    "    # save_code=True,\n",
    ")\n",
    "\n",
    "device = \"cuda:3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_configs = {\n",
    "    \"surrogate\": dict(\n",
    "        output_dim=32,\n",
    "    ),\n",
    "    \"loss\": dict(\n",
    "        name=\"KDLoss\",\n",
    "        gamma1=1.0,\n",
    "        gamma2=1.0,\n",
    "        temp_student=0.2,\n",
    "        temp_teacher=1,\n",
    "    ),\n",
    "    \"optimizer\": dict(\n",
    "        lr=1e-3,\n",
    "        weight_decay=1e-4,\n",
    "    )\n",
    "}\n",
    "run.config.update(train_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from scripts.train_surrogate import train_surrogate_experiment, train_local_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/blue/thai/hoangx/projects/explain-representation/exrep/registry.py:196: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tensor = torch.load(file_path, map_location=map_location)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact imagenet-1k-first-20-take-2000_images:latest, 230.91MB. 3 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n",
      "Done. 0:0:0.7\n",
      "INFO:__main__:Encoding shape: torch.Size([2000, 20])\n",
      "INFO:__main__:Embeddings shape: torch.Size([2000, 2048])\n",
      "INFO:__main__:Image dataset: Dataset({\n",
      "    features: ['image', 'label'],\n",
      "    num_rows: 2000\n",
      "})\n",
      "INFO:__main__:XY dataset: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['inputs', 'targets', 'label'],\n",
      "        num_rows: 1800\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['inputs', 'targets', 'label'],\n",
      "        num_rows: 200\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "assert device is not None, \"Please provide a device to run the experiment on.\"\n",
    "\n",
    "embedding_artifact_name = \"imagenet-1k-first-20-take-2000_target-embeddings_mocov3-resnet50\"\n",
    "image_artifact_name = \"imagenet-1k-first-20-take-2000_images\"\n",
    "output_phase_name = \"surrogate\"\n",
    "\n",
    "encoding = load_tensor(\n",
    "    base_name=\"imagenet\",\n",
    "    phase=\"local-encoding\",\n",
    "    identifier=\"agglomerative\",\n",
    "    file_name=f\"local-encoding_{run.config.num_clusters}.pt\",\n",
    "    map_location=device,\n",
    "    wandb_run=run,\n",
    ")\n",
    "embeddings = load_tensor(\n",
    "    \"embeddings.pt\",\n",
    "    artifact_name=embedding_artifact_name,\n",
    "    map_location=device,\n",
    "    wandb_run=run,\n",
    ")\n",
    "images_path = get_artifact(\n",
    "    image_artifact_name,\n",
    "    wandb_run=run,\n",
    ").download()\n",
    "images_dataset = datasets.load_from_disk(images_path)\n",
    "labels_dataset = images_dataset.remove_columns([\"image\"])\n",
    "\n",
    "if isinstance(embeddings, list):\n",
    "    embeddings = torch.cat(embeddings, dim=0)\n",
    "embeddings_dataset = datasets.Dataset.from_dict({\"targets\": embeddings})\n",
    "encoding_dataset = datasets.Dataset.from_dict({\"inputs\": encoding})\n",
    "\n",
    "xy_dataset = datasets.concatenate_datasets(\n",
    "    [encoding_dataset, embeddings_dataset, labels_dataset],\n",
    "    axis=1\n",
    ").with_format(\"torch\").train_test_split(0.1, shuffle=False, seed=random_state)\n",
    "\n",
    "logger.info(\"Encoding shape: %s\", encoding.shape)\n",
    "logger.info(\"Embeddings shape: %s\", embeddings.shape)\n",
    "logger.info(\"Image dataset: %s\", images_dataset)\n",
    "logger.info(\"XY dataset: %s\", xy_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9918730854988098"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from typing import Optional\n",
    "\n",
    "def compute_baseline_loss(\n",
    "    loss_config: dict,\n",
    "    val_dataset: datasets.Dataset,\n",
    "    keys: torch.Tensor,\n",
    "    batch_size: int,\n",
    "    device: Optional[str] = None,\n",
    "):\n",
    "    assert device is not None, \"Please provide a device to run the experiment on.\"\n",
    "    temp_teacher = loss_config[\"temp_teacher\"]\n",
    "    losses = []\n",
    "    with torch.inference_mode():\n",
    "        for batch in val_dataset.iter(batch_size=batch_size):\n",
    "            features, targets, labels = itemgetter(\"inputs\", \"targets\", \"label\")(batch)\n",
    "            \n",
    "            sim_teacher = targets.to(device) @ keys.T      # shape (B x B)\n",
    "            prob_student = torch.ones_like(sim_teacher, device=device) / sim_teacher.shape[1]\n",
    "\n",
    "            loss_batch = torch.nn.functional.kl_div(\n",
    "                input=torch.log(prob_student), \n",
    "                target=torch.softmax(sim_teacher / temp_teacher, dim=-1), \n",
    "                reduction=\"batchmean\",\n",
    "            )\n",
    "            losses.append(loss_batch)\n",
    "    # technically mean of means is not the same as mean of all losses\n",
    "    # but in this case it should be fine\n",
    "    return torch.stack(losses).mean().item()\n",
    "\n",
    "compute_baseline_loss(run.config.loss, xy_dataset[\"test\"], embeddings, batch_size=512, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nop:\n",
    "    def nop(*args, **kw): pass\n",
    "    def __getattr__(self, _): return self.nop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d32559220e94277900aabdda37aa63e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd9fc03dc4e4b529a94eacf0973a4d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:shap:num_full_subsets = 1\n",
      "INFO:shap:remaining_weight_vector = array([0.214078  , 0.15111388, 0.12041888, 0.10275744, 0.09174772,\n",
      "       0.0846902 , 0.08027925, 0.07784655, 0.07706808])\n",
      "INFO:shap:num_paired_subset_sizes = 9\n",
      "INFO:shap:weight_left = np.float64(0.7032951454518925)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75eb732725e347f1a544c4e23c1f8634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[1]\n",
      "[ 0  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[2]\n",
      "[ 0  1  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[3]\n",
      "[ 0  1  2  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[4]\n",
      "[ 0  1  2  3  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[5]\n",
      "[ 0  1  2  3  4  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[6]\n",
      "[ 0  1  2  3  4  5  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[7]\n",
      "[ 0  1  2  3  4  5  6  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[8]\n",
      "[ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[9]\n",
      "[ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 18 19]\n",
      "[10]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 11 12 13 14 15 16 17 18 19]\n",
      "[11]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 12 13 14 15 16 17 18 19]\n",
      "[12]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 13 14 15 16 17 18 19]\n",
      "[13]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 14 15 16 17 18 19]\n",
      "[14]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 15 16 17 18 19]\n",
      "[15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 16 17 18 19]\n",
      "[16]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 17 18 19]\n",
      "[17]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 18 19]\n",
      "[18]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 19]\n",
      "[19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18]\n",
      "[ 0  1  4  6  7  9 10 16 17 18]\n",
      "[ 6 10 11 12 13 14 15 18]\n",
      "[ 0  1  2  3  4  5  7  8  9 16 17 19]\n",
      "[ 1  9 11]\n",
      "[ 0  2  3  4  5  6  7  8 10 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  4  5  7 11 13 15]\n",
      "[ 3  6  8  9 10 12 14 16 17 18 19]\n",
      "[ 0  1  3  9 12 14 15 18]\n",
      "[ 2  4  5  6  7  8 10 11 13 16 17 19]\n",
      "[ 9 16]\n",
      "[ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 15 17 18 19]\n",
      "[ 0  5 10 12 14 15]\n",
      "[ 1  2  3  4  6  7  8  9 11 13 16 17 18 19]\n",
      "[ 2  4  5 16 18 19]\n",
      "[ 0  1  3  6  7  8  9 10 11 12 13 14 15 17]\n",
      "[ 4 11 13 15 18 19]\n",
      "[ 0  1  2  3  5  6  7  8  9 10 12 14 16 17]\n",
      "[ 0  1  9 11 14]\n",
      "[ 2  3  4  5  6  7  8 10 12 13 15 16 17 18 19]\n",
      "[ 1  5  8  9 10 15 16 17]\n",
      "[ 0  2  3  4  6  7 11 12 13 14 18 19]\n",
      "[ 3  4 11]\n",
      "[ 0  1  2  5  6  7  8  9 10 12 13 14 15 16 17 18 19]\n",
      "[ 2  8 10 11 13 14 15 16 18]\n",
      "[ 0  1  3  4  5  6  7  9 12 17 19]\n",
      "[ 6 15]\n",
      "[ 0  1  2  3  4  5  7  8  9 10 11 12 13 14 16 17 18 19]\n",
      "[ 2  7 10 11 13]\n",
      "[ 0  1  3  4  5  6  8  9 12 14 15 16 17 18 19]\n",
      "[ 6  9 10 12]\n",
      "[ 0  1  2  3  4  5  7  8 11 13 14 15 16 17 18 19]\n",
      "[14 18]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 15 16 17 19]\n",
      "[ 1 12]\n",
      "[ 0  2  3  4  5  6  7  8  9 10 11 13 14 15 16 17 18 19]\n",
      "[ 6 14 15]\n",
      "[ 0  1  2  3  4  5  7  8  9 10 11 12 13 16 17 18 19]\n",
      "[4 7]\n",
      "[ 0  1  2  3  5  6  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 2  3  4  7  8 11 15 17 19]\n",
      "[ 0  1  5  6  9 10 12 13 14 16 18]\n",
      "[ 5 14 16]\n",
      "[ 0  1  2  3  4  6  7  8  9 10 11 12 13 15 17 18 19]\n",
      "[ 7 13 15 17 19]\n",
      "[ 0  1  2  3  4  5  6  8  9 10 11 12 14 16 18]\n",
      "[ 5  6  8  9 14 15 17 19]\n",
      "[ 0  1  2  3  4  7 10 11 12 13 16 18]\n",
      "[5 7 9]\n",
      "[ 0  1  2  3  4  6  8 10 11 12 13 14 15 16 17 18 19]\n",
      "[0 9]\n",
      "[ 1  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 4  8 14 15]\n",
      "[ 0  1  2  3  5  6  7  9 10 11 12 13 16 17 18 19]\n",
      "[ 0  2  4  8 11 14 15 16 18]\n",
      "[ 1  3  5  6  7  9 10 12 13 17 19]\n",
      "[ 4  6  8 10 13 15]\n",
      "[ 0  1  2  3  5  7  9 11 12 14 16 17 18 19]\n",
      "[ 2  3 10 13 14 15 16 19]\n",
      "[ 0  1  4  5  6  7  8  9 11 12 17 18]\n",
      "[ 0  3  4  5 13 17]\n",
      "[ 1  2  6  7  8  9 10 11 12 14 15 16 18 19]\n",
      "[ 5 11 12]\n",
      "[ 0  1  2  3  4  6  7  8  9 10 13 14 15 16 17 18 19]\n",
      "[ 4  7 11]\n",
      "[ 0  1  2  3  5  6  8  9 10 12 13 14 15 16 17 18 19]\n",
      "[15 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 16 17 18]\n",
      "[10 14 17 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 11 12 13 15 16 18]\n",
      "[ 1  4  5  6  9 14 15 18 19]\n",
      "[ 0  2  3  7  8 10 11 12 13 16 17]\n",
      "[ 1  4  5  6 11 12 18]\n",
      "[ 0  2  3  7  8  9 10 13 14 15 16 17 19]\n",
      "[ 1  2  3  5  6  9 13 18 19]\n",
      "[ 0  4  7  8 10 11 12 14 15 16 17]\n",
      "[ 0 18 19]\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17]\n",
      "[ 2  9 10 13]\n",
      "[ 0  1  3  4  5  6  7  8 11 12 14 15 16 17 18 19]\n",
      "[ 4 13 19]\n",
      "[ 0  1  2  3  5  6  7  8  9 10 11 12 14 15 16 17 18]\n",
      "[5 9]\n",
      "[ 0  1  2  3  4  6  7  8 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 2  7 11]\n",
      "[ 0  1  3  4  5  6  8  9 10 12 13 14 15 16 17 18 19]\n",
      "[ 7 18]\n",
      "[ 0  1  2  3  4  5  6  8  9 10 11 12 13 14 15 16 17 19]\n",
      "[ 0  1  8 14 19]\n",
      "[ 2  3  4  5  6  7  9 10 11 12 13 15 16 17 18]\n",
      "[ 3  4  5  6  7 11 13 14 15]\n",
      "[ 0  1  2  8  9 10 12 16 17 18 19]\n",
      "[ 0  2  4  5  6 12 13 14 15]\n",
      "[ 1  3  7  8  9 10 11 16 17 18 19]\n",
      "[ 9 15]\n",
      "[ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 16 17 18 19]\n",
      "[ 2  4  5  7 13 15]\n",
      "[ 0  1  3  6  8  9 10 11 12 14 16 17 18 19]\n",
      "[ 4 14 16]\n",
      "[ 0  1  2  3  5  6  7  8  9 10 11 12 13 15 17 18 19]\n",
      "[ 0  2  4  6  7 12 13 15 16 18]\n",
      "[ 1  5 11 13 16]\n",
      "[ 0  2  3  4  6  7  8  9 10 12 14 15 17 18 19]\n",
      "[ 6 13 14 18]\n",
      "[ 0  1  2  3  4  5  7  8  9 10 11 12 15 16 17 19]\n",
      "[ 1  2  3  4  8 12 18 19]\n",
      "[ 0  5  6  7  9 10 11 13 14 15 16 17]\n",
      "[ 0  5  6  9 10 11 14 17]\n",
      "[ 1  2  3  4  7  8 12 13 15 16 18 19]\n",
      "[10 14]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 11 12 13 15 16 17 18 19]\n",
      "[ 1  4  6  7  9 14 18]\n",
      "[ 0  2  3  5  8 10 11 12 13 15 16 17 19]\n",
      "[ 9 10 12 15 18]\n",
      "[ 0  1  2  3  4  5  6  7  8 11 13 14 16 17 19]\n",
      "[ 4 11 12]\n",
      "[ 0  1  2  3  5  6  7  8  9 10 13 14 15 16 17 18 19]\n",
      "[ 2  6  9 10 11 14]\n",
      "[ 0  1  3  4  5  7  8 12 13 15 16 17 18 19]\n",
      "[ 1  2  3  5 12]\n",
      "[ 0  4  6  7  8  9 10 11 13 14 15 16 17 18 19]\n",
      "[ 1 17]\n",
      "[ 0  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 18 19]\n",
      "[ 3 10]\n",
      "[ 0  1  2  4  5  6  7  8  9 11 12 13 14 15 16 17 18 19]\n",
      "[ 3  4  9 10]\n",
      "[ 0  1  2  5  6  7  8 11 12 13 14 15 16 17 18 19]\n",
      "[ 1  6 13 19]\n",
      "[ 0  2  3  4  5  7  8  9 10 11 12 14 15 16 17 18]\n",
      "[ 3  8 10 11 16 19]\n",
      "[ 0  1  2  4  5  6  7  9 12 13 14 15 17 18]\n",
      "[ 0  3  9 18]\n",
      "[ 1  2  4  5  6  7  8 10 11 12 13 14 15 16 17 19]\n",
      "[ 5 14 17 19]\n",
      "[ 0  1  2  3  4  6  7  8  9 10 11 12 13 15 16 18]\n",
      "[ 3 10 13 14 15 16 18]\n",
      "[ 0  1  2  4  5  6  7  8  9 11 12 17 19]\n",
      "[8 9]\n",
      "[ 0  1  2  3  4  5  6  7 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  2  3  7 10 11 12 13 15 16]\n",
      "[ 0 19]\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18]\n",
      "[10 15 16 17 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 11 12 13 14 18]\n",
      "[ 5 10]\n",
      "[ 0  1  2  3  4  6  7  8  9 11 12 13 14 15 16 17 18 19]\n",
      "[10 18]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 11 12 13 14 15 16 17 19]\n",
      "[3 4]\n",
      "[ 0  1  2  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 6  9 14 16]\n",
      "[ 0  1  2  3  4  5  7  8 10 11 12 13 15 17 18 19]\n",
      "[ 0  6  7  8 14]\n",
      "[ 1  2  3  4  5  9 10 11 12 13 15 16 17 18 19]\n",
      "[ 0  1  2  4  5  8 12 16 17 19]\n",
      "[4 6]\n",
      "[ 0  1  2  3  5  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 5  6  9 10 11 12 13 15 18 19]\n",
      "[ 3 12 16 17]\n",
      "[ 0  1  2  4  5  6  7  8  9 10 11 13 14 15 18 19]\n",
      "[ 3 13 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:shap:np.sum(w_aug) = np.float64(19.999999999999996)\n",
      "INFO:shap:np.sum(self.kernelWeights) = np.float64(0.9999999999999996)\n",
      "INFO:shap:phi = array([-0.01262849, -0.00427697, -0.00091514,  0.        , -0.00992   ,\n",
      "       -0.00571036, -0.00448445, -0.01092365, -0.00076525, -0.000886  ,\n",
      "       -0.03073997, -0.03894176, -0.01954492, -0.01091697, -0.03279042,\n",
      "       -0.00590338, -0.02714465, -0.00986548, -0.00555533, -0.00303933])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.01262849, -0.00427697, -0.00091514,  0.        , -0.00992   ,\n",
       "       -0.00571036, -0.00448445, -0.01092365, -0.00076525, -0.000886  ,\n",
       "       -0.03073997, -0.03894176, -0.01954492, -0.01091697, -0.03279042,\n",
       "       -0.00590338, -0.02714465, -0.00986548, -0.00555533, -0.00303933])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import ceil\n",
    "\n",
    "from functools import partial\n",
    "import shap\n",
    "from tqdm.notebook import tqdm    \n",
    "\n",
    "def test_fn(X):\n",
    "    results = []\n",
    "    for row in tqdm(X):\n",
    "        indices = np.where(row == 0)[0]\n",
    "        # print(np.where(row == 1)[0])\n",
    "        \n",
    "        masked_encoding = encoding.clone()\n",
    "        masked_encoding[:, indices] = 0\n",
    "        perturbed_encoding_dataset = datasets.Dataset.from_dict({\"inputs\": masked_encoding})\n",
    "\n",
    "        perturbed_dataset = datasets.concatenate_datasets(\n",
    "            [perturbed_encoding_dataset, embeddings_dataset, labels_dataset],\n",
    "            axis=1\n",
    "        ).with_format(\"torch\").train_test_split(0.1, shuffle=False, seed=random_state)\n",
    "\n",
    "        model, logs = train_local_representation(\n",
    "            alpha=0,\n",
    "            model_config=run.config.surrogate,\n",
    "            loss_config=run.config.loss,\n",
    "            optimizer_config=run.config.optimizer,\n",
    "            train_dataset=perturbed_dataset[\"train\"],\n",
    "            val_dataset=perturbed_dataset[\"test\"],\n",
    "            keys=embeddings,\n",
    "            groups=None,\n",
    "            eval_downstream=False,\n",
    "            wandb_run=Nop(),\n",
    "            num_epochs=40,\n",
    "            batch_size=512,\n",
    "            log_every_n_steps=0,\n",
    "            device=device,\n",
    "        )\n",
    "        best_val_loss = min(log[\"val_loss\"] for log in logs[\"val\"])\n",
    "        # logger.info(\"Best validation loss: %s\", best_val_loss)\n",
    "        results.append(best_val_loss)\n",
    "    return np.array(results)\n",
    "\n",
    "shap_explainer = shap.KernelExplainer(test_fn, np.zeros((1, encoding.shape[1])))\n",
    "shap_values = shap_explainer.shap_values(np.ones((encoding.shape[1], )), nsamples=200)\n",
    "shap_values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.054,  0.018,  0.004, -0.   ,  0.042,  0.024,  0.019,  0.046,\n",
       "        0.003,  0.004,  0.131,  0.166,  0.083,  0.046,  0.14 ,  0.025,\n",
       "        0.116,  0.042,  0.024,  0.013])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(shap_values / shap_values.sum(), 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exrep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
